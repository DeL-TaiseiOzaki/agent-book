{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_4En0wobPGBv"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_core==0.3.0 langchain_openai==0.2.0 langgraph==0.2.23"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"agent-book\""
      ],
      "metadata": {
        "id": "Bxe0ElLDPKmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "from typing import Annotated\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "class State(BaseModel):\n",
        "    query: str = Field(..., description=\"ユーザーからの質問\")\n",
        "    current_role: str = Field(\n",
        "        default=\"\", description=\"選定された回答ロール\"\n",
        "    )\n",
        "    messages: Annotated[list[str], operator.add] = Field(\n",
        "        default=[], description=\"回答履歴\"\n",
        "    )\n",
        "    current_judge: bool = Field(\n",
        "        default=False, description=\"品質チェックの結果\"\n",
        "    )\n",
        "    judgement_reason: str = Field(\n",
        "        default=\"\", description=\"品質チェックの判定理由\"\n",
        "    )"
      ],
      "metadata": {
        "id": "yEMmbO9_PwX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROLES = {\n",
        "    \"1\": {\n",
        "        \"name\": \"一般知識エキスパート\",\n",
        "        \"description\": \"幅広い分野の一般的な質問に答える\",\n",
        "        \"details\": \"幅広い分野の一般的な質問に対して、正確で分かりやすい回答を提供してください。\"\n",
        "    },\n",
        "    \"2\": {\n",
        "        \"name\": \"生成AI製品エキスパート\",\n",
        "        \"description\": \"生成AIや関連製品、技術に関する専門的な質問に答える\",\n",
        "        \"details\": \"生成AIや関連製品、技術に関する専門的な質問に対して、最新の情報と深い洞察を提供してください。\"\n",
        "    },\n",
        "    \"3\": {\n",
        "        \"name\": \"カウンセラー\",\n",
        "        \"description\": \"個人的な悩みや心理的な問題に対してサポートを提供する\",\n",
        "        \"details\": \"個人的な悩みや心理的な問題に対して、共感的で支援的な回答を提供し、可能であれば適切なアドバイスも行ってください。\"\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "81MxpeCcl1zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.runnables import ConfigurableField\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)\n",
        "# 後からmax_tokensの値を変更できるように、変更可能なフィールドを宣言\n",
        "llm = llm.configurable_fields(max_tokens=ConfigurableField(id='max_tokens'))"
      ],
      "metadata": {
        "id": "Uba4clqnR0Xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "def selection_node(state: State) -> dict[str, Any]:\n",
        "    query = state.query\n",
        "    role_options = \"\\n\".join([f\"{k}. {v['name']}: {v['description']}\" for k, v in ROLES.items()])\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "\"\"\"質問を分析し、最も適切な回答担当ロールを選択してください。\n",
        "\n",
        "選択肢:\n",
        "{role_options}\n",
        "\n",
        "回答は選択肢の番号（1、2、または3）のみを返してください。\n",
        "\n",
        "質問: {query}\n",
        "\"\"\".strip()\n",
        "    )\n",
        "    # 選択肢の番号のみを返すことを期待したいため、max_tokensの値を1に変更\n",
        "    chain = prompt | llm.with_config(configurable=dict(max_tokens=1)) | StrOutputParser()\n",
        "    role_number = chain.invoke({\"role_options\": role_options, \"query\": query})\n",
        "\n",
        "    selected_role = ROLES[role_number.strip()][\"name\"]\n",
        "    return {\"current_role\": selected_role}"
      ],
      "metadata": {
        "id": "pEo1g0DRiOmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answering_node(state: State) -> dict[str, Any]:\n",
        "    query = state.query\n",
        "    role = state.current_role\n",
        "    role_details = \"\\n\".join([f\"- {v['name']}: {v['details']}\" for v in ROLES.values()])\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "\"\"\"あなたは{role}として回答してください。以下の質問に対して、あなたの役割に基づいた適切な回答を提供してください。\n",
        "\n",
        "役割の詳細:\n",
        "{role_details}\n",
        "\n",
        "質問: {query}\n",
        "\n",
        "回答:\"\"\".strip()\n",
        "    )\n",
        "    chain = prompt | llm | StrOutputParser()\n",
        "    answer = chain.invoke({\"role\": role, \"role_details\": role_details, \"query\": query})\n",
        "    return {\"messages\": [answer]}"
      ],
      "metadata": {
        "id": "cSaxaP4Viya4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Judgement(BaseModel):\n",
        "    judge: bool = Field(default=False, description=\"判定結果\")\n",
        "    reason: str = Field(default=\"\", description=\"判定理由\")\n",
        "\n",
        "def check_node(state: State) -> dict[str, Any]:\n",
        "    query = state.query\n",
        "    answer = state.messages[-1]\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "\"\"\"以下の回答の品質をチェックし、問題がある場合は'False'、問題がない場合は'True'を回答してください。\n",
        "また、その判断理由も説明してください。\n",
        "\n",
        "ユーザーからの質問: {query}\n",
        "回答: {answer}\n",
        "\"\"\".strip()\n",
        "    )\n",
        "    chain = prompt | llm.with_structured_output(Judgement)\n",
        "    result: Judgement = chain.invoke({\"query\": query, \"answer\": answer})\n",
        "\n",
        "    return {\n",
        "        \"current_judge\": result.judge,\n",
        "        \"judgement_reason\": result.reason\n",
        "    }"
      ],
      "metadata": {
        "id": "b2OwQeFOmJKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph\n",
        "\n",
        "workflow = StateGraph(State)"
      ],
      "metadata": {
        "id": "fn_SRJHFmRkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow.add_node(\"selection\", selection_node)\n",
        "workflow.add_node(\"answering\", answering_node)\n",
        "workflow.add_node(\"check\", check_node)"
      ],
      "metadata": {
        "id": "M89Q5i38mapZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow.set_entry_point(\"selection\")\n",
        "workflow.add_edge(\"selection\", \"answering\")\n",
        "workflow.add_edge(\"answering\", \"check\")"
      ],
      "metadata": {
        "id": "UfvD6usqmnfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"check\",\n",
        "    lambda state: state.current_judge,\n",
        "    {True: END, False: \"selection\"}\n",
        ")"
      ],
      "metadata": {
        "id": "sGLI2oBXmpPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compiled = workflow.compile()"
      ],
      "metadata": {
        "id": "3enuf4qxmtKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_state = State(query=\"生成AIについて教えてください\")\n",
        "result = compiled.invoke(initial_state)"
      ],
      "metadata": {
        "id": "IrOMXTwamvqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "YVY8b-xAmz9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result[\"messages\"][-1])"
      ],
      "metadata": {
        "id": "XXYKgkqwm5ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_state = State(query=\"生成AIについて教えてください\")\n",
        "result = await compiled.ainvoke(initial_state)\n",
        "result"
      ],
      "metadata": {
        "id": "FYiulEmujTOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage\n",
        "\n",
        "initial_state = State(query=\"生成AIについて教えてください\")\n",
        "for step in compiled.stream(initial_state, stream_mode=\"values\"):\n",
        "    print(step)"
      ],
      "metadata": {
        "id": "ngd1l6FGkuOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install graphviz libgraphviz-dev pkg-config\n",
        "!pip install pygraphviz"
      ],
      "metadata": {
        "id": "rWSfoFYenBD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(compiled.get_graph().draw_png())"
      ],
      "metadata": {
        "id": "kPg8DAZ8x8_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XJfwpsgGyZ77"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}